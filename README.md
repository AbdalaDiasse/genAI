# LLM & LVM Playground Monorepo

Welcome to the **LLM & LVM Playground**, a comprehensive monorepo template for experimenting with **Large Language Models (LLMs)** and **Large Vision Models (LVMs)**.

This repo is designed for **intermediate to advanced machine learning practitioners** who want to explore training, inference, quantization, deployment, and benchmarking across cloud, local, and edge environments.

---

## ğŸ“ Repository Structure

```plaintext
llm-lvm-playground/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ llm/                  # Fine-tuning and pretraining of LLMs
â”‚   â””â”€â”€ lvm/                  # Fine-tuning of LVMs (ViT, Diffusers, etc.)
â”‚
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ llm/                  # Inference with Hugging Face, vLLM, DeepSpeed
â”‚   â””â”€â”€ lvm/                  # Inference for vision models
â”‚
â”œâ”€â”€ quantization/
â”‚   â”œâ”€â”€ bitsandbytes/         # 8-bit / 4-bit quantization examples
â”‚   â”œâ”€â”€ gptq/                 # GPTQ quantized models
â”‚   â””â”€â”€ awq/                  # Activation-aware weight quantization
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ cloud/                # AWS, GCP deployment (EC2, SageMaker, Vertex AI)
â”‚   â”œâ”€â”€ local/                # FastAPI serving with Docker
â”‚   â”œâ”€â”€ edge/                 # ONNX / TensorRT for Jetson, Raspberry Pi
â”‚   â”œâ”€â”€ triton/               # NVIDIA Triton Inference Server
â”‚   â””â”€â”€ onnx_tensorrt/        # ONNX â†’ TensorRT optimized inference
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ prompts/              # Prompt sets for evaluation
â”‚   â”œâ”€â”€ benchmark.py          # Performance and latency tests
â”‚   â”œâ”€â”€ eval_harness.py       # EleutherAI Evaluation Harness
â”‚   â””â”€â”€ results/              # Output logs and metrics
â”‚
â”œâ”€â”€ model_zoo/
â”‚   â”œâ”€â”€ llms.md               # Recommended LLMs with quick usage guide
â”‚   â””â”€â”€ lvms.md               # Recommended LVMs with quick usage guide
â”‚
â””â”€â”€ README.md                 # You are here
```

---

## ğŸš€ Key Features

- ğŸ”§ **Training**: Fine-tuning and pretraining for LLaMA, Mistral, Falcon, ViT, SD
- ğŸ§  **Inference**: Serve models with Hugging Face, vLLM, DeepSpeed, TGI
- ğŸ“¦ **Quantization**: Use bitsandbytes (4/8-bit), GPTQ, AWQ to optimize models
- ğŸ“¡ **Deployment**: Cloud, local server (FastAPI), and edge device setups
- ğŸ“Š **Evaluation**: Evaluate with EleutherAI Harness and benchmark scripts
- ğŸ§­ **Model Zoo**: Curated list of top-performing open-source LLMs & LVMs

---

## ğŸ› ï¸ Setup Instructions

```bash
# Clone this repository
git clone https://github.com/your-org/llm-lvm-playground.git
cd llm-lvm-playground

# (Optional) Create Python virtual environment
python3 -m venv venv
source venv/bin/activate

# Install core dependencies (submodules have their own requirements.txt files)
pip install -r requirements.txt
```

Each module (`training/`, `inference/`, etc.) has its own README with usage instructions.

---

## ğŸ“š Documentation Index

- [`training/`](./training/) â€“ Fine-tune or pretrain LLMs and LVMs  
- [`inference/`](./inference/) â€“ Efficient inference with vLLM, Hugging Face, DeepSpeed  
- [`quantization/`](./quantization/) â€“ Quantize with bitsandbytes, GPTQ, AWQ  
- [`deployment/`](./deployment/) â€“ Deploy on cloud, locally or on edge devices  
- [`evaluation/`](./evaluation/) â€“ Run eval harness, measure latency/memory  
- [`model_zoo/`](./model_zoo/) â€“ Curated list of top open-source models with examples  

---

## ğŸ¤ Contributing

We welcome all contributions!

- Add more fine-tuning or inference examples
- Improve deployment guides or Docker setups
- Contribute benchmark results or evaluations
- Submit issues or feature requests

Please submit pull requests against `main` with a clear description of the change.

---

## ğŸ“ License

This project is licensed under the **Apache 2.0 License**.

Note: Refer to each modelâ€™s specific license in the `model_zoo/` directory when using or modifying individual models.

---

## ğŸ™Œ Credits

This repo builds on the amazing work from:

- [Hugging Face](https://huggingface.co/)
- [vLLM](https://github.com/vllm-project/vllm)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)
- [EleutherAI](https://github.com/EleutherAI/lm-evaluation-harness)
- [Meta AI](https://ai.meta.com/)
- [Stability AI](https://stability.ai/)
- [NVIDIA](https://developer.nvidia.com/triton-inference-server)

---

**Maintainer**: [Your Name / Org]  
ğŸ“« Contact: [your-email@example.com]  
â­ Star the repo if you find it useful!


Let me know if you want this packaged as a `.zip` with placeholder folders and README files included.
